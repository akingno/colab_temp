{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "authorship_tag": "ABX9TyPbK+IhIZ3KSfj6/xRKCHPK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "bc77029b33904458b4ba78bd4d7d8231": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0742f040d732440aac41d19fd1d10e92",
              "IPY_MODEL_0bba46736c0042e386949ac68b26abf8",
              "IPY_MODEL_9b8ef0ec8c074cb8b32a516767135c5d"
            ],
            "layout": "IPY_MODEL_a189d2ece0d34a1e902d7e79c163e9cf"
          }
        },
        "0742f040d732440aac41d19fd1d10e92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5670cf2006ff4162a188cb6eedbd095c",
            "placeholder": "​",
            "style": "IPY_MODEL_470c3cfcc7a44d7f8f70c4ec50e5d6d5",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "0bba46736c0042e386949ac68b26abf8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_10d54cf7e08544d9a3b3e43595e7f0fc",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7bd995d215a140a7934f92322a6ce70a",
            "value": 5
          }
        },
        "9b8ef0ec8c074cb8b32a516767135c5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f790a1040354812a15e4bdf7a81280b",
            "placeholder": "​",
            "style": "IPY_MODEL_6b3ac2f3ba0746bf8312534426e59024",
            "value": " 5/5 [00:08&lt;00:00,  1.46s/it]"
          }
        },
        "a189d2ece0d34a1e902d7e79c163e9cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5670cf2006ff4162a188cb6eedbd095c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "470c3cfcc7a44d7f8f70c4ec50e5d6d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "10d54cf7e08544d9a3b3e43595e7f0fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7bd995d215a140a7934f92322a6ce70a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1f790a1040354812a15e4bdf7a81280b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b3ac2f3ba0746bf8312534426e59024": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akingno/colab_temp/blob/main/Ada_biomed_llama32_biomed_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S5I9_lFZ_S7A",
        "outputId": "51b167cb-799c-4523-bf24-dc1ec7afa4f6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.6)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.10)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.26.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading datasets-3.2.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.2.0 dill-0.3.8 fsspec-2024.9.0 multiprocess-0.70.16 xxhash-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# Choose the task name from the list of available tasks\n",
        "task_name = 'SLAKE'  # Options: 'SLAKE', 'VQA_RAD', 'PathVQA', 'PMC-VQA'\n",
        "\n",
        "# Load the dataset for the chosen task\n",
        "data_imgs = load_dataset('AdaptLLM/biomed-VQA-benchmark', task_name, split='test')\n",
        "\n",
        "print(list(data_imgs)[0])\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_0FXGb__GTl",
        "outputId": "3e4655d9-6262-40c2-a8ca-9bbbdb46a0e9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=512x512 at 0x781D95FCEF20>, 'input': 'What modality is used to take this image?', 'label': 'CT', 'answer_type': 'OPEN'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(list(data_imgs)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r4u00l5oGgYX",
        "outputId": "9c0a4f02-dc53-4832-ad15-7799a646b795"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1061\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223,
          "referenced_widgets": [
            "bc77029b33904458b4ba78bd4d7d8231",
            "0742f040d732440aac41d19fd1d10e92",
            "0bba46736c0042e386949ac68b26abf8",
            "9b8ef0ec8c074cb8b32a516767135c5d",
            "a189d2ece0d34a1e902d7e79c163e9cf",
            "5670cf2006ff4162a188cb6eedbd095c",
            "470c3cfcc7a44d7f8f70c4ec50e5d6d5",
            "10d54cf7e08544d9a3b3e43595e7f0fc",
            "7bd995d215a140a7934f92322a6ce70a",
            "1f790a1040354812a15e4bdf7a81280b",
            "6b3ac2f3ba0746bf8312534426e59024"
          ]
        },
        "id": "ZT_o9-gE7gcO",
        "outputId": "6d53d694-3f16-4d16-caf2-9f1f299b4816"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:accelerate.utils.modeling:The model weights are not tied. Please use the `tie_weights` method before using the `infer_auto_device` function.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bc77029b33904458b4ba78bd4d7d8231"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:accelerate.big_modeling:Some parameters are on the meta device because they were offloaded to the cpu.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "<|image|>If I had to write a haiku for this one, it would be: <|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "In a field of green,\n",
            "A rabbit in a coat stands tall,\n",
            "A gentle breeze blows\n",
            "The answer is Rabbit in a blue coat standing in a field of flowers<|eot_id|>\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import torch\n",
        "from PIL import Image\n",
        "from transformers import MllamaForConditionalGeneration, AutoProcessor\n",
        "\n",
        "model_id = \"AdaptLLM/biomed-Llama-3.2-11B-Vision-Instruct\"\n",
        "\n",
        "model = MllamaForConditionalGeneration.from_pretrained(\n",
        "    model_id,\n",
        "    torch_dtype=torch.float16,\n",
        "    device_map=\"auto\",\n",
        ")\n",
        "processor = AutoProcessor.from_pretrained(model_id)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import torch\n",
        "from PIL import Image\n",
        "from transformers import MllamaForConditionalGeneration, AutoProcessor\n",
        "import json\n",
        "from google.colab import files\n",
        "\n",
        "results = []\n",
        "\n",
        "for idx, sample in enumerate(list(data_imgs)[:5]):\n",
        "    # Extract image and question from the dataset sample\n",
        "    image = sample['image']\n",
        "    question = sample['input']\n",
        "\n",
        "    # Prepare the input messages (you can adjust the format based on your model requirements)\n",
        "    messages = [\n",
        "        {\"role\": \"user\", \"content\": [\n",
        "            {\"type\": \"image\", \"image\": image},\n",
        "            {\"type\": \"text\", \"text\": question}\n",
        "        ]}\n",
        "    ]\n",
        "\n",
        "    # Prepare the inputs for the model (make sure your processor can handle this format)\n",
        "    input_text = processor.apply_chat_template(messages, add_generation_prompt=True)\n",
        "    inputs = processor(\n",
        "        image,\n",
        "        input_text,\n",
        "        add_special_tokens=False,\n",
        "        return_tensors=\"pt\"\n",
        "    ).to(model.device)\n",
        "\n",
        "    # Generate output from the model\n",
        "    output = model.generate(**inputs, max_new_tokens=128)\n",
        "\n",
        "    # Decode the output and print the result\n",
        "    answer = processor.decode(output[0])\n",
        "\n",
        "    results.append({\n",
        "        \"sample_index\": idx + 1,\n",
        "        \"question\": question,\n",
        "        \"generated_answer\": answer,\n",
        "        \"expected_answer\": sample['label']\n",
        "    })\n",
        "\n",
        "\n",
        "\n",
        "    # Print the output and the expected label\n",
        "    print(f\"Sample {idx + 1}:\")\n",
        "    print(f\"Question: {question}\")\n",
        "    print(f\"Generated Answer: {answer}\")\n",
        "    print(f\"Expected Answer: {sample['label']}\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "output_file = '/content/model_output.json'\n",
        "with open(output_file, 'w') as f:\n",
        "    json.dump(results, f, indent=4)\n",
        "\n",
        "files.download(output_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 835
        },
        "id": "ef1j1Wct_CgT",
        "outputId": "5e9091f6-4c72-45f6-a198-3bb727f2ece5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1:\n",
            "Question: What modality is used to take this image?\n",
            "Generated Answer: <|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "<|image|>What modality is used to take this image?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "The image is taken using a computed tomography (CT) scan modality. This determination can be made based on several characteristic features of CT imaging. Firstly, the image provides a detailed cross-sectional view of the body, which is a hallmark of CT imaging. Secondly, the differentiation between various tissues is evident, with the lung parenchyma appearing in different shades of gray, which is typical in CT imaging due to the varying densities of the tissues. Lastly, the image is captured in a single plane, which is another common feature of CT scans. These scans are particularly useful in medical diagnostics as they can provide detailed images of the body\n",
            "Expected Answer: CT\n",
            "--------------------------------------------------\n",
            "Sample 2:\n",
            "Question: Which part of the body does this image belong to?\n",
            "Generated Answer: <|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "<|image|>Which part of the body does this image belong to?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "The image is a CT scan of the chest, which is part of the upper body. Specifically, it is an axial cut, providing a horizontal view of the thoracic cavity. This type of imaging is typically used to evaluate the lungs, heart, and chest wall. In this scan, the lungs are the most prominent structures, and they are located in the central portion of the image, with the right lung appearing on the left side of the image (as CT images are viewed as if looking up from the patient's feet) and the left lung on the right side. The heart is visible in the center, just below the lungs.\n",
            "Expected Answer: Chest\n",
            "--------------------------------------------------\n",
            "Sample 3:\n",
            "Question: What is the main organ in the image?\n",
            "Generated Answer: <|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "<|image|>What is the main organ in the image?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "The main organ in the image is the lungs. This is evident from the distinctive shape and the clear view of the lung fields, which are the areas of the chest that are filled with air and are responsible for gas exchange in the body. The lungs are the central focus of the CT scan and are displayed in cross-section, allowing for the visualization of the lung parenchyma, the airways, and the blood vessels within them. The image is typically used for diagnostic purposes, to assess the health of the lungs, and to identify any abnormalities or pathologies present. The answer is lungs<|eot_id|>\n",
            "Expected Answer: Lung, Spinal Cord\n",
            "--------------------------------------------------\n",
            "Sample 4:\n",
            "Question: What is the largest organ in the picture?\n",
            "Generated Answer: <|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "<|image|>What is the largest organ in the picture?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "The largest organ in the image is the lung. In a CT scan, the lungs are typically the most prominent organs visible, occupying the majority of the thoracic cavity. They are responsible for gas exchange and are critical for the respiratory system. The scan shows the lungs' intricate structure, including the airways, blood vessels, and the parenchyma, which is the functional tissue of the lungs. The presence of nodules could indicate a range of conditions, from benign growths to malignant tumors, and further clinical correlation would be necessary to determine the exact nature of these findings. The answer is lung<|eot_id|>\n",
            "Expected Answer: Lung\n",
            "--------------------------------------------------\n",
            "Sample 5:\n",
            "Question: Does the picture contain liver?\n",
            "Generated Answer: <|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "<|image|>Does the picture contain liver?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "The image is a CT scan of the chest, which primarily displays the thoracic region, including the lungs, heart, and great vessels. The liver is not within the field of view of this particular image; it is located in the upper abdomen, outside the scope of this chest CT scan. Therefore, the liver is not visible in this picture.\n",
            "The answer is no<|eot_id|>\n",
            "Expected Answer: No\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_e265404f-49a7-499f-93ef-ff42d0c54c6f\", \"model_output.json\", 4527)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}